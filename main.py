import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, status
from starlette.websockets import WebSocketState
import os
import whisper
import google.generativeai as genai
from dotenv import load_dotenv
import httpx
from typing import Union, Dict, Optional, List
import random
import asyncio
import json
import wave
import io

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

app = FastAPI()
# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã® audio_io.py ã¨åŒã˜è¨­å®š ---
RATE = 24000
CHANNELS = 1
SAMPLE_WIDTH = 2  # 16-bit (int16) = 2 bytes

# --- è¨­å®š ---
AVAILABLE_SPEAKER_IDS = [2, 3, 1, 8, 10, 14]
VOICEVOX_BASE_URL = "http://127.0.0.1:50021"
# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒé€ã‚‹ã¹ãèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã¨åˆã‚ã›ã‚‹)
SERVER_AUTH_TOKEN = os.getenv("SERVER_AUTH_TOKEN", "dev-token") 

# --- ãƒ¢ãƒ‡ãƒ«ã¨APIã®æº–å‚™ ---
try:
    model = whisper.load_model("base")
    print("âœ… Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚")
except Exception as e:
    model = None
    print(f"âŒ Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

try:
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•°ã«GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    genai.configure(api_key=gemini_api_key)
    gemini_model = genai.GenerativeModel("gemini-flash-latest")
    print("âœ… Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å®Œäº†ã€‚")
except Exception as e:
    gemini_model = None
    print(f"âŒ Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å¤±æ•—: {e}")

# --- èªè¨¼ ---
async def validate_token(websocket: WebSocket) -> str:
    """WebSocketæ¥ç¶šãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¤œè¨¼ã™ã‚‹"""
    auth_header = websocket.headers.get("Authorization")
    if not auth_header:
        print("âŒ èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        raise WebSocketDisconnect(code=status.WS_1008_POLICY_VIOLATION, reason="Missing Authorization header")
    
    try:
        scheme, token = auth_header.split()
        if scheme.lower() != "bearer" or token != SERVER_AUTH_TOKEN:
            raise ValueError("Invalid token")
    except ValueError:
        print(f"âŒ ç„¡åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³ã§ã™: {auth_header}")
        raise WebSocketDisconnect(code=status.WS_1008_POLICY_VIOLATION, reason="Invalid token")
    
    print("âœ… ãƒˆãƒ¼ã‚¯ãƒ³èªè¨¼æˆåŠŸã€‚")
    return token 

# --- æ¥ç¶šç®¡ç† ---
class ConnectionManager:
    def __init__(self):
        # mic_id ã‚’ã‚­ãƒ¼ã«ã€å†ç”Ÿç”¨(playback)WebSocketã‚’ä¿æŒ
        self.playback_connections: Dict[str, WebSocket] = {}

    async def connect_playback(self, websocket: WebSocket, mic_id: str):
        """
        å†ç”Ÿç”¨(Playback)ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¥ç¶š
        (æ³¨: acceptã¯å‘¼ã³å‡ºã—å…ƒã® websocket_endpoint ã§è¡Œã„ã¾ã™)
        """
        # await websocket.accept()  # â˜…â˜…â˜… ã“ã“ã§ã¯ accept ã—ãªã„ â˜…â˜…â˜…
        
        if mic_id in self.playback_connections:
            # ã™ã§ã«åŒã˜IDã®å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã„ã‚Œã°å¤ã„æ–¹ã‚’åˆ‡æ–­
            print(f"âš ï¸  '{mic_id}' ã®å¤ã„å†ç”Ÿæ¥ç¶šã‚’å¼·åˆ¶åˆ‡æ–­ã—ã¾ã™ã€‚")
            try:
                await self.playback_connections[mic_id].close(code=status.WS_1001_GOING_AWAY, reason="New connection replaced")
            except Exception:
                pass # ã™ã§ã«åˆ‡ã‚Œã¦ã„ã¦ã‚‚ç„¡è¦–
        self.playback_connections[mic_id] = websocket
        print(f"âœ… [Playback] ãƒã‚¤ã‚¯ '{mic_id}' ãŒæ¥ç¶šã—ã¾ã—ãŸã€‚")

    def disconnect_playback(self, mic_id: str):
        """å†ç”Ÿç”¨(Playback)ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆ‡æ–­"""
        if mic_id in self.playback_connections:
            del self.playback_connections[mic_id]
            print(f"âŒ [Playback] ãƒã‚¤ã‚¯ '{mic_id}' ãŒåˆ‡æ–­ã—ã¾ã—ãŸã€‚")

    async def get_playback_ws(self, mic_id: str) -> Optional[WebSocket]:
        """æŒ‡å®šã•ã‚ŒãŸmic_idã®å†ç”Ÿç”¨WebSocketã‚’å–å¾—ã™ã‚‹"""
        ws = self.playback_connections.get(mic_id)
        if ws and ws.client_state == WebSocketState.CONNECTED:
            return ws
        elif ws:
            # æ¥ç¶šãŒåˆ‡ã‚Œã¦ã„ã‚‹å ´åˆã¯è¾æ›¸ã‹ã‚‰å‰Šé™¤
            self.disconnect_playback(mic_id)
            return None
        return None

    async def broadcast_text(self, mic_id: str, text: str):
        """æŒ‡å®šã•ã‚ŒãŸmic_idã®å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡"""
        ws = await self.get_playback_ws(mic_id)
        if ws:
            try:
                await ws.send_json({"type": "ai_text", "text": text})
                print(f"â„¹ï¸  [Playback] '{mic_id}' ã¸ãƒ†ã‚­ã‚¹ãƒˆé€ä¿¡: {text[:20]}...")
            except Exception as e:
                print(f"âŒ [Playback] '{mic_id}' ã¸ã®ãƒ†ã‚­ã‚¹ãƒˆé€ä¿¡å¤±æ•—: {e}")
                self.disconnect_playback(mic_id)

    async def broadcast_audio(self, mic_id: str, audio_data: bytes):
        """æŒ‡å®šã•ã‚ŒãŸmic_idã®å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«éŸ³å£°(bytes)ã‚’é€ä¿¡"""
        ws = await self.get_playback_ws(mic_id)
        if ws:
            try:
                await ws.send_bytes(audio_data)
                print(f"ğŸ”Š [Playback] '{mic_id}' ã¸éŸ³å£° {len(audio_data)} bytes é€ä¿¡ã€‚")
            except Exception as e:
                print(f"âŒ [Playback] '{mic_id}' ã¸ã®éŸ³å£°é€ä¿¡å¤±æ•—: {e}")
                self.disconnect_playback(mic_id)

    async def broadcast_tts_done(self, mic_id: str):
        """æŒ‡å®šã•ã‚ŒãŸmic_idã®å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«tts_doneã‚’é€ä¿¡"""
        ws = await self.get_playback_ws(mic_id)
        if ws:
            try:
                await ws.send_json({"type": "tts_done"})
                print(f"â„¹ï¸  [Playback] '{mic_id}' ã¸ tts_done é€ä¿¡ã€‚")
            except Exception as e:
                print(f"âŒ [Playback] '{mic_id}' ã¸ã® tts_done é€ä¿¡å¤±æ•—: {e}")
                self.disconnect_playback(mic_id)

manager = ConnectionManager()


# --- é–¢æ•°å®šç¾© (VOICEVOX) ---
async def generate_voicevox_audio(text: str, speaker_id: int) -> Union[bytes, None]:
    """VOICEVOX APIã‚’å‘¼ã³å‡ºã—ã€éŸ³å£°(WAV)ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹"""
    async with httpx.AsyncClient() as client:
        try:
            params = {"text": text, "speaker": speaker_id}
            res_query = await client.post(f"{VOICEVOX_BASE_URL}/audio_query", params=params)
            res_query.raise_for_status()
            audio_query = res_query.json()
            
            # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ(16000Hz)ã¨åˆã‚ã›ã‚‹ãŸã‚ã€
            # VOICEVOXã®å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã‚’ RATE (16000) ã«å¤‰æ›´ã™ã‚‹
            audio_query["outputSamplingRate"] = RATE
            
            headers = {"Content-Type": "application/json"}
            res_synth = await client.post(
                f"{VOICEVOX_BASE_URL}/synthesis",
                params={"speaker": speaker_id},
                json=audio_query, # å¤‰æ›´æ¸ˆã¿ã® audio_query ã‚’é€ä¿¡
                headers=headers,
                timeout=20.0
            )
            res_synth.raise_for_status()
            
            print(f"âœ… VOICEVOXã«ã‚ˆã‚‹éŸ³å£°åˆæˆã«æˆåŠŸã—ã¾ã—ãŸ (Rate: {RATE}Hz)ã€‚")
            return res_synth.content
            
        except httpx.RequestError as e:
            print(f"âŒ VOICEVOX APIã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e} (VOICEVOXã‚¢ãƒ—ãƒªã¯èµ·å‹•ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ)")
            return None
        except httpx.HTTPStatusError as e:
            print(f"âŒ VOICEVOX APIã‹ã‚‰ã‚¨ãƒ©ãƒ¼ãŒè¿”ã•ã‚Œã¾ã—ãŸ: {e.response.status_code}")
            return None
# --- AIå‡¦ç†ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ ---

async def process_audio_to_ai_response(mic_id: str, audio_data: bytes):
    """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€AIå‡¦ç†ã‚’è¡Œã„ã€å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«å¿œå¿œç­”ã‚’é€ä¿¡ã™ã‚‹"""
    
    if not model or not gemini_model:
        print("ãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ãŸã‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    print(f"ğŸ¤ [AI Process] ãƒã‚¤ã‚¯ '{mic_id}' ã®å‡¦ç†é–‹å§‹ (éŸ³å£°: {len(audio_data)} bytes)")

    try:
        # 1. Whisperã§æ–‡å­—èµ·ã“ã—
        temp_path = f"temp_{mic_id}.wav"
        try:
            with wave.open(temp_path, "wb") as wf:
                wf.setnchannels(CHANNELS)
                wf.setsampwidth(SAMPLE_WIDTH)
                wf.setframerate(RATE)
                wf.writeframes(audio_data)
        except Exception as e:
            print(f"âŒ .wav ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return
        
        result = model.transcribe(temp_path, fp16=False)
        transcribed_text = result["text"].strip()
        os.remove(temp_path)
        
        if not transcribed_text:
            print("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸã€‚")
            return
        print(f"âœ¨ æ–‡å­—èµ·ã“ã—çµæœ ({mic_id}): {transcribed_text}")

        # 2. Geminiã§å¿œç­”ç”Ÿæˆã¨æ„Ÿæƒ…åˆ†æ
        prompt = f"""# å‘½ä»¤
ã‚ãªãŸã¯ã€å…¥åŠ›ã•ã‚ŒãŸæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆã™ã‚‹AIã§ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã‚’å³æ ¼ã«å®ˆã‚Šã€å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

# ç¦æ­¢äº‹é …
- ã‚ãªãŸè‡ªèº«ã®è¨€è‘‰ã§å¿œç­”ã—ãŸã‚Šã€ä¼šè©±ã‚’è©¦ã¿ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
- åˆ†æçµæœã®JSONä»¥å¤–ã«ã€èª¬æ˜ã€å‰ç½®ãã€ç›¸æ§Œãªã©ã®ä½™è¨ˆãªãƒ†ã‚­ã‚¹ãƒˆã‚’çµ¶å¯¾ã«å‡ºåŠ›ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚

# å‡¦ç†å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
{transcribed_text}

# JSONç”Ÿæˆãƒ«ãƒ¼ãƒ«
## emotion
- ã€Œå‡¦ç†å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆã€ã‹ã‚‰è©±è€…ã®æ„Ÿæƒ…ã‚’æ¨æ¸¬ã—ã€ã€Œå–œã³ã€ã€Œæ€’ã‚Šã€ã€Œæ‚²ã—ã¿ã€ã€Œå¹³å¸¸ã€ã®ã„ãšã‚Œã‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

## UserSpeech
- ã€Œå‡¦ç†å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆã€ã®å†…å®¹ã‚’ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦è‡ªç„¶ã§ä¸å¯§ãªæ—¥æœ¬èªã®æ–‡ç« ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚
  - é¡”æ–‡å­—ã€çµµæ–‡å­—ã€å°‚é–€çš„ãªæ©Ÿæ¢°èªã¯ä½¿ç”¨ã—ãªã„ã€‚
  - 1æ–‡ã‚’60ã€œ90æ–‡å­—ç¨‹åº¦ã«åã‚ã€èª­ç‚¹ã¯1æ–‡ã«2ã¤ã¾ã§ã«ã™ã‚‹ã€‚
  - æ„å›³ã‚’å°Šé‡ã—ã¤ã¤ã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã™ããšã€ãƒ“ã‚¸ãƒã‚¹ã™ããªã„è¡¨ç¾ã«ã™ã‚‹ã€‚
  - è³ªå•ã‚„ä¾é ¼ã®å ´åˆã¯ã€ç›¸æ‰‹ã«å¤±ç¤¼ã®ãªã„ä¸å¯§ãªè¡¨ç¾ã«å¤‰æ›ã™ã‚‹ã€‚
  - å¦å®šçš„ãªå†…å®¹ã®å ´åˆã¯ã€ç›¸æ‰‹ã‚’ä¸å¿«ã«ã•ã›ãªã„æŸ”ã‚‰ã‹ã„è¡¨ç¾ã«å¤‰æ›ã™ã‚‹ã€‚

# å‡ºåŠ›å½¢å¼
- ç”Ÿæˆã—ãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
- Markdownã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯(```json)ã¯ä¸è¦ã§ã™ã€‚

{{
  "emotion": "ï¼ˆã“ã“ã«æ¨æ¸¬ã—ãŸæ„Ÿæƒ…ï¼‰",
  "UserSpeech": "ï¼ˆã“ã“ã«å¤‰æ›ã—ãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆï¼‰"
}}
"""
        response = gemini_model.generate_content(prompt)
        
        ai_response_text = ""
        try:
            # ```json ... ``` ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã‚’å‰Šé™¤
            cleaned_response = response.text.strip().removeprefix("```json").removesuffix("```").strip()
            
            data = json.loads(cleaned_response)
            emotion = data.get("emotion", "ä¸æ˜")
            ai_response_text = data.get("UserSpeech", "")

            print(f"ğŸ˜ƒ æ„Ÿæƒ…åˆ†æçµæœ ({mic_id}): {emotion}")
            print(f"ğŸ’¬ Geminiã‹ã‚‰ã®å¿œç­” ({mic_id}): {ai_response_text}")

        except (json.JSONDecodeError, AttributeError) as e:
            print(f"âš ï¸ Geminiã‹ã‚‰ã®å¿œç­”ã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ã€å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾ä½¿ã†
            ai_response_text = response.text

        if not ai_response_text:
            print("AIã®å¿œç­”ãŒç©ºã§ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            return

        # 3. (â˜…ç›®æ¨™é”æˆ) Geminiã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
        await manager.broadcast_text(mic_id, ai_response_text)

        # 4. VOICEVOXã§éŸ³å£°åˆæˆ
        selected_speaker_id = random.choice(AVAILABLE_SPEAKER_IDS)
        print(f"ğŸ—£ï¸  ä»Šå›é¸æŠã•ã‚ŒãŸè©±è€…ID: {selected_speaker_id}")
        voice_data = await generate_voicevox_audio(ai_response_text, speaker_id=selected_speaker_id)

        # 5. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€ã‚Šè¿”ã™
        if voice_data:
            
            raw_pcm_data = b""
            duration_s = 0.0

            try:
                # 5a. ãƒ¡ãƒ¢ãƒªä¸Šã§WAVãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€raw PCMãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’æŠ½å‡º
                with io.BytesIO(voice_data) as wav_bytes:
                    with wave.open(wav_bytes, "rb") as wf:
                        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ä¸€å¿œç¢ºèª
                        if wf.getframerate() != RATE or wf.getsampwidth() != SAMPLE_WIDTH or wf.getnchannels() != CHANNELS:
                            print(f"âŒ VOICEVOXã®å½¢å¼ ({wf.getframerate()}Hz, {wf.getsampwidth()}byte, {wf.getnchannels()}ch) ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™ã€‚")
                            raw_pcm_data = b"" # â˜… å‡¦ç†ã‚’ä¸­æ–­ã™ã‚‹ãŸã‚ã«ç©ºã«ã™ã‚‹
                        else:
                            # å½¢å¼ãŒæ­£ã—ã„å ´åˆã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
                            raw_pcm_data = wf.readframes(wf.getnframes())
                            bytes_per_second = RATE * CHANNELS * SAMPLE_WIDTH
                            duration_s = len(raw_pcm_data) / bytes_per_second

            except wave.Error as e:
                print(f"âŒ VOICEVOXã‹ã‚‰ã®WAVãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            except Exception as e:
                print(f"âŒ WAVãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")


            if raw_pcm_data:
                # 5b. raw PCM ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
                await manager.broadcast_audio(mic_id, raw_pcm_data)
                
                # 5c. éŸ³å£°ã®å†ç”Ÿæ™‚é–“ã ã‘å¾…æ©Ÿ
                # JitterBuffer(200ms) + ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ã‚’è€ƒæ…®ã—å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
                await asyncio.sleep(duration_s + 0.3) 
                
                # 5d. ãƒŸãƒ¥ãƒ¼ãƒˆè§£é™¤é€šçŸ¥ã‚’é€ä¿¡
                await manager.broadcast_tts_done(mic_id)
        
        print(f"âœ… [AI Process] ãƒã‚¤ã‚¯ '{mic_id}' ã®å‡¦ç†å®Œäº†ã€‚")

    except Exception as e:
        print(f"âŒ [AI Process] å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


# --- WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---

@app.websocket("/ws/{mic_id}")
async def websocket_endpoint(
    websocket: WebSocket, 
    mic_id: str,
    token: str = Depends(validate_token) # èªè¨¼ã‚’å®Ÿè¡Œ
):
    
    # ã©ã‚“ãªæ¥ç¶šã§ã‚‚ã€ã¾ãšãƒãƒ³ãƒ‰ã‚·ã‚§ã‚¤ã‚¯ã‚’å®Œäº†ã•ã›ã‚‹
    await websocket.accept()
    
    is_playback_client = False
    audio_buffer: List[bytes] = []

    try:
        # 1. æ¥ç¶šãŒç¢ºç«‹ã—ãŸå¾Œã€æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚‹
        first_msg_raw = await websocket.receive() # dict ãŒè¿”ã‚‹
        
        if first_msg_raw.get("type") != "websocket.receive":
            # ãŠãã‚‰ãåˆ‡æ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã©
            raise WebSocketDisconnect(code=status.WS_1011_INTERNAL_ERROR, reason="Unexpected message type")

        first_msg_text = first_msg_raw.get("text")
        first_msg_bytes = first_msg_raw.get("bytes")

        if first_msg_text is not None:
            # --- Playbackã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å‡¦ç† ---
            try:
                data = json.loads(first_msg_text)
                if data.get("type") == "hello" and data.get("role") == "playback":
                    is_playback_client = True
                    await manager.connect_playback(websocket, mic_id)
                else:
                    print(f"âŒ '{mic_id}' ã‹ã‚‰ä¸æ˜ãªJSONã€‚åˆ‡æ–­ã—ã¾ã™: {first_msg_text}")
                    raise WebSocketDisconnect(code=status.WS_1003_UNSUPPORTED_DATA, reason="Unknown JSON message")
            except json.JSONDecodeError:
                print(f"âŒ '{mic_id}' ã‹ã‚‰ä¸æ­£ãªJSONãƒ†ã‚­ã‚¹ãƒˆã€‚åˆ‡æ–­ã—ã¾ã™: {first_msg_text}")
                raise WebSocketDisconnect(code=status.WS_1003_UNSUPPORTED_DATA, reason="Invalid JSON message")
        
        elif first_msg_bytes is not None:
            # --- Senderã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å‡¦ç† (æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ) ---
            print(f"âœ… [Sender] ãƒã‚¤ã‚¯ '{mic_id}' ãŒæ¥ç¶šã—ã¾ã—ãŸ (æœ€åˆã®éŸ³å£°å—ä¿¡)ã€‚")
            audio_buffer.append(first_msg_bytes)
        
        else:
            # bytes/strä»¥å¤–ã¯åˆ‡æ–­
            print(f"âŒ '{mic_id}' ã‹ã‚‰ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚åˆ‡æ–­ã—ã¾ã™ã€‚")
            raise WebSocketDisconnect(code=status.WS_1003_UNSUPPORTED_DATA, reason="Empty message")

        # 2. æ¥ç¶šã‚¿ã‚¤ãƒ—ã”ã¨ï¼ˆPlayback / Senderï¼‰ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        if is_playback_client:
            # --- Playbackã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ«ãƒ¼ãƒ— ---
            while True:
                msg_raw = await websocket.receive() # dict ãŒè¿”ã‚‹
                if msg_raw.get("type") == "websocket.disconnect":
                    raise WebSocketDisconnect(code=msg_raw.get("code", 1000))
                
                # Playbackå´ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ¥ã‚‹ã“ã¨ã¯æƒ³å®šã—ã¦ã„ãªã„
                text_data = msg_raw.get("text")
                if text_data:
                    print(f"â„¹ï¸  [Playback] '{mic_id}' ã‹ã‚‰äºˆæœŸã›ã¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {text_data}")

        else:
            # --- Senderã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ«ãƒ¼ãƒ— ---
            while True:
                msg_raw = await websocket.receive() # dict ãŒè¿”ã‚‹
                if msg_raw.get("type") == "websocket.disconnect":
                    raise WebSocketDisconnect(code=msg_raw.get("code", 1000))

                bytes_data = msg_raw.get("bytes")
                text_data = msg_raw.get("text")
                
                if bytes_data is not None:
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                    audio_buffer.append(bytes_data)
                
                elif text_data is not None:
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ¶å¾¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
                    try:
                        msg_data = json.loads(text_data)
                        if msg_data.get("type") == "stop":
                            # VADã®çµ‚äº†é€šçŸ¥
                            print(f"â„¹ï¸  [Sender] '{mic_id}' ã‹ã‚‰ 'stop' ã‚’å—ä¿¡ã€‚")
                            if not audio_buffer:
                                print("âš ï¸  [Sender] 'stop' ã‚’å—ä¿¡ã—ã¾ã—ãŸãŒã€éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãŒç©ºã§ã™ã€‚")
                                continue
                            
                            full_audio_data = b"".join(audio_buffer)
                            audio_buffer.clear()
                            
                            # AIå‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’éåŒæœŸã§å®Ÿè¡Œ
                            asyncio.create_task(process_audio_to_ai_response(mic_id, full_audio_data))
                        
                        else:
                            print(f"âš ï¸  [Sender] '{mic_id}' ã‹ã‚‰ä¸æ˜ãªåˆ¶å¾¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {text_data}")
                    
                    except json.JSONDecodeError:
                         print(f"âš ï¸  [Sender] '{mic_id}' ã‹ã‚‰ä¸æ­£ãªJSON: {text_data}")
                
                else:
                    print(f"âš ï¸  [Sender] '{mic_id}' ã‹ã‚‰ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {msg_raw}")


    except WebSocketDisconnect:
        if is_playback_client:
            manager.disconnect_playback(mic_id)
        else:
            print(f"âŒ [Sender] ãƒã‚¤ã‚¯ '{mic_id}' ãŒåˆ‡æ–­ã—ã¾ã—ãŸã€‚")
            # SenderãŒåˆ‡æ–­ã—ãŸéš›ã€ãƒãƒƒãƒ•ã‚¡ã«ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ã‚Œã°å‡¦ç†ã™ã‚‹
            if audio_buffer:
                print(f"â„¹ï¸  [Sender] '{mic_id}' åˆ‡æ–­æ™‚ã«æ®‹ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
                full_audio_data = b"".join(audio_buffer)
                audio_buffer.clear()
                asyncio.create_task(process_audio_to_ai_response(mic_id, full_audio_data))

    except Exception as e:
        print(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ({mic_id}, Playback={is_playback_client}): {e}")
        if is_playback_client:
            manager.disconnect_playback(mic_id)


if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)