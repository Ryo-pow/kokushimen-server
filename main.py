import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, status
from fastapi.security import APIKeyHeader
import os
import time
import json
import random
import asyncio
from typing import Union, Dict, Set

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import numpy as np
from faster_whisper import WhisperModel
import google.generativeai as genai
from dotenv import load_dotenv
import httpx

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ– ---
app = FastAPI()

# --- èªè¨¼è¨­å®š ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æœŸå¾…ã™ã‚‹APIã‚­ãƒ¼ã‚’å–å¾—
EXPECTED_API_KEY = os.getenv("SERVER_AUTH_TOKEN", "dev-token-secret")
# "Authorization" ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿å–ã‚‹ãŸã‚ã®è¨­å®š
api_key_header = APIKeyHeader(name="Authorization", auto_error=False)

async def get_api_key(auth_header: str = Depends(api_key_header)):
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œè¨¼ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸æ­£ãªã‚‰WebSocketæ¥ç¶šã‚’æ‹’å¦ã™ã‚‹"""
    if not auth_header or len(auth_header.split()) != 2:
        return None
    
    scheme, _, token = auth_header.partition(" ")
    if scheme.lower() == "bearer" and token == EXPECTED_API_KEY:
        return token
    return None

# --- æ¥ç¶šç®¡ç† ---
class ConnectionManager:
    """WebSocketæ¥ç¶šã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self):
        self.senders: Dict[str, WebSocket] = {}
        self.playbacks: Set[WebSocket] = set()
        self.audio_buffers: Dict[str, bytearray] = {}

    async def connect(self, websocket: WebSocket):
        await websocket.accept()

    def disconnect(self, websocket: WebSocket):
        sender_to_remove = next((stream_id for stream_id, ws in self.senders.items() if ws == websocket), None)
        if sender_to_remove:
            del self.senders[sender_to_remove]
            if sender_to_remove in self.audio_buffers:
                del self.audio_buffers[sender_to_remove]
        
        self.playbacks.discard(websocket)

    def add_sender(self, stream_id: str, websocket: WebSocket):
        self.senders[stream_id] = websocket
        self.audio_buffers[stream_id] = bytearray()
        print(f"âœ… é€ä¿¡ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ '{stream_id}' ãŒç™»éŒ²ã•ã‚Œã¾ã—ãŸã€‚")

    def add_playback(self, websocket: WebSocket):
        self.playbacks.add(websocket)
        print("âœ… å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒç™»éŒ²ã•ã‚Œã¾ã—ãŸã€‚")

    def append_audio_data(self, stream_id: str, data: bytes):
        if stream_id in self.audio_buffers:
            self.audio_buffers[stream_id].extend(data)

    def get_and_clear_audio_data(self, stream_id: str) -> bytes:
        data = self.audio_buffers.get(stream_id, b'')
        if data:
            self.audio_buffers[stream_id].clear()
        return bytes(data)

    async def broadcast_audio_chunks(self, audio_data: bytes, chunk_size: int):
        """å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå…¨å“¡ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã§é€ä¿¡"""
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i+chunk_size]
            # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«éåŒæœŸã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦åŒæ™‚ã«é€ä¿¡
            tasks = [ws.send_bytes(chunk) for ws in self.playbacks]
            await asyncio.gather(*tasks, return_exceptions=True)
            # ãƒãƒ£ãƒ³ã‚¯ã®å†ç”Ÿæ™‚é–“ã«åˆã‚ã›ã¦å¾…æ©Ÿ (16kHz/16bit/mono)
            await asyncio.sleep(chunk_size / (16000 * 2))

    async def broadcast_json(self, json_data: dict):
        """å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå…¨å“¡ã«JSONãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡"""
        tasks = [ws.send_json(json_data) for ws in self.playbacks]
        await asyncio.gather(*tasks, return_exceptions=True)

manager = ConnectionManager()

# --- è¨­å®š ---
VOICEVOX_BASE_URL = "http://127.0.0.1:50021"
# 16kHz, 16-bit, mono ã® 200ms åˆ†ã®ãƒã‚¤ãƒˆæ•°ï¼ˆ6400Bï¼‰
TTS_CHUNK_SIZE = 16000 * 2 * 1 * 200 // 1000
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èµ·å‹•ã®ã—ãã„å€¤ï¼ˆmsï¼‰: æ—¢å®š 1200ms è²¯ã¾ã£ãŸã‚‰è‡ªå‹•å‡¦ç†
MIN_PROCESS_MS = int(os.getenv("MIN_PROCESS_MS", "1200"))
# 20ms=640B ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŸºæº–ã«è¨ˆç®—
STREAM_THRESHOLD_BYTES = max(640, (MIN_PROCESS_MS // 20) * 640)

# --- ãƒ¢ãƒ‡ãƒ«ã¨APIã®æº–å‚™ ---
try:
    # CPU: "int8", GPU: "float16" or "int8_float16"
    whisper_model = WhisperModel("base", device="cpu", compute_type="int8")
    print("âœ… faster-whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚")
except Exception as e:
    whisper_model = None
    print(f"âŒ faster-whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

try:
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•°ã«GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    genai.configure(api_key=gemini_api_key)
    gemini_model = genai.GenerativeModel('gemini-1.5-flash')
    print("âœ… Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å®Œäº†ã€‚")
except Exception as e:
    gemini_model = None
    print(f"âŒ Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å¤±æ•—: {e}")

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def generate_voicevox_audio(text: str, speaker_id: int) -> Union[bytes, None]:
    """VOICEVOX APIã‚’å‘¼ã³å‡ºã—ã¦éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹"""
    async with httpx.AsyncClient() as client:
        try:
            # 1. audio_queryã®ä½œæˆ
            params = {"text": text, "speaker": speaker_id}
            res_query = await client.post(f"{VOICEVOX_BASE_URL}/audio_query", params=params, timeout=10.0)
            res_query.raise_for_status()
            audio_query = res_query.json()
            # å‡ºåŠ›ã‚’ 16kHz/mono ã«çµ±ä¸€ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä»•æ§˜ã«åˆã‚ã›ã‚‹ï¼‰
            try:
                audio_query["outputSamplingRate"] = 16000
                audio_query["outputStereo"] = False
            except Exception:
                pass
            
            # 2. synthesisã®å®Ÿè¡Œ
            headers = {"Content-Type": "application/json"}
            res_synth = await client.post(
                f"{VOICEVOX_BASE_URL}/synthesis",
                params={"speaker": speaker_id},
                json=audio_query,
                headers=headers,
                timeout=20.0
            )
            res_synth.raise_for_status()
            return res_synth.content
        except httpx.RequestError as e:
            print(f"âŒ VOICEVOX APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def pcm_s16le_to_float32(audio_data: bytes) -> np.ndarray:
    """ç”ŸPCM(s16le)ãƒ‡ãƒ¼ã‚¿ã‚’WhisperãŒå‡¦ç†ã§ãã‚‹float32å½¢å¼ã«å¤‰æ›"""
    return np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

# --- WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.websocket("/ws/{mic_id}")
async def websocket_endpoint(websocket: WebSocket, mic_id: str, token: str = Depends(get_api_key)):
    if not token:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        print("âŒ èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒç„¡åŠ¹ãªãŸã‚æ¥ç¶šã‚’æ‹’å¦ã—ã¾ã—ãŸã€‚")
        return

    await manager.connect(websocket)
    # URLã®mic_idã‚’stream_idã¨ã—ã¦å³æ™‚ç™»éŒ²
    stream_id = mic_id
    manager.add_sender(stream_id, websocket)

    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã”ã¨ã®å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
    is_processing = False

    async def run_pipeline(full_audio_data: bytes):
        nonlocal is_processing
        try:
            if len(full_audio_data) < 1600:  # 100ms æœªæº€ã¯ç„¡è¦–
                print("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return
            if not whisper_model or not gemini_model:
                print("ãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ãŸã‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return

            t_start = time.time()
            # 1. Whisper æ–‡å­—èµ·ã“ã—
            audio_np = pcm_s16le_to_float32(full_audio_data)
            segments, _ = whisper_model.transcribe(audio_np, beam_size=5, language="ja", vad_filter=True)
            transcribed_text = "".join([s.text for s in segments]).strip()
            t_asr = time.time()
            if not transcribed_text:
                print("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸã€‚")
                return
            print(f"âœ¨ æ–‡å­—èµ·ã“ã—çµæœ: {transcribed_text}")

            # 2. Gemini ã§å¿œç­” + æ„Ÿæƒ…
            prompt = f"""
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã€Œ{transcribed_text}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
            ä»¥ä¸‹ã®2ã¤ã®é …ç›®ã‚’å«ã‚€JSONå½¢å¼ã§ã€çµæœã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

            1. "emotion": ç™ºè¨€ã‹ã‚‰æœ€ã‚‚å¼·ãæ„Ÿã˜ã‚‰ã‚Œã‚‹æ„Ÿæƒ…ã‚’ã€Œå–œã³ã€ã€Œæ€’ã‚Šã€ã€Œæ‚²ã—ã¿ã€ã€Œå¹³å¸¸ã€ã®ã„ãšã‚Œã‹ä¸€ã¤ã§ç¤ºã—ã¦ãã ã•ã„ã€‚
            2. "reply": è¦ªåˆ‡ã§ç°¡æ½”ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦ã®å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            """
            response = await gemini_model.generate_content_async(prompt)
            ai_response_json_str = response.text
            try:
                if "```json" in ai_response_json_str:
                    ai_response_json_str = ai_response_json_str.split('```json\n')[1].split('\n```')[0]
                ai_response_data = json.loads(ai_response_json_str)
                ai_emotion = ai_response_data.get("emotion", "å¹³å¸¸")
                ai_response_text = ai_response_data.get("reply", "ã™ã¿ã¾ã›ã‚“ã€ã†ã¾ãèãå–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            except Exception as e:
                print(f"âŒ Geminiã®å¿œç­”(JSON)ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                ai_emotion = "å¹³å¸¸"
                ai_response_text = "ã™ã¿ã¾ã›ã‚“ã€å°‘ã—èª¿å­ãŒæ‚ªã„ã‚ˆã†ã§ã™ã€‚"
            t_llm = time.time()
            print(f"ğŸ˜Š æ„Ÿæƒ…åˆ†æçµæœ: {ai_emotion}")
            print(f"ğŸ’¬ Geminiã‹ã‚‰ã®å¿œç­”: {ai_response_text}")

            # 3. VOICEVOX åˆæˆï¼ˆæ„Ÿæƒ…ã§è©±è€…åˆ‡æ›¿ï¼‰
            speaker_map = {"å–œã³": 3, "æ‚²ã—ã¿": 1, "æ€’ã‚Š": 8, "å¹³å¸¸": 2}
            selected_speaker_id = speaker_map.get(ai_emotion, speaker_map["å¹³å¸¸"])
            print(f"ğŸ—£ï¸  è©±è€…ID '{selected_speaker_id}' ã‚’é¸æŠã—ã¾ã—ãŸã€‚")
            voice_wav = await generate_voicevox_audio(ai_response_text, speaker_id=selected_speaker_id)
            t_tts = time.time()

            # 4. WAV â†’ PCM æŠ½å‡ºã— 200ms ãƒãƒ£ãƒ³ã‚¯ã§é…ä¿¡
            if voice_wav:
                import io, wave
                with wave.open(io.BytesIO(voice_wav), "rb") as wf:
                    sr = wf.getframerate()
                    ch = wf.getnchannels()
                    sw = wf.getsampwidth()
                    pcm = wf.readframes(wf.getnframes())
                    if not (sr == 16000 and ch == 1 and sw == 2):
                        print(f"âš ï¸ VOICEVOXå‡ºåŠ›ã®å½¢å¼ãŒæƒ³å®šå¤–: sr={sr} ch={ch} sw={sw}")
                # 200ms=6400B ã«åˆ†å‰²é€ä¿¡
                await manager.broadcast_audio_chunks(pcm, TTS_CHUNK_SIZE)
                await manager.broadcast_json({"type": "tts_done"})
                print("â„¹ï¸  ãƒŸãƒ¥ãƒ¼ãƒˆè§£é™¤ã®ãŸã‚ã®å®Œäº†é€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")

            t_end = time.time()
            print(f"â±ï¸  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: [ASR: {t_asr - t_start:.2f}s] [LLM: {t_llm - t_asr:.2f}s] [TTS: {t_tts - t_llm:.2f}s] [Total: {t_end - t_start:.2f}s]")
        finally:
            is_processing = False

    try:
        while True:
            data = await websocket.receive()

            # JSONå½¢å¼ã®åˆ¶å¾¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
            if "text" in data:
                try:
                    msg_json = json.loads(data["text"])
                    msg_type = msg_json.get("type")
                    
                    # ç™ºè©±çµ‚äº†ã®é€šçŸ¥ã‚’å—ã‘å–ã£ãŸã‚‰ã€ä¸€é€£ã®å‡¦ç†ã‚’é–‹å§‹
                    if msg_type == "stop":
                        print(f"ğŸ¤ ãƒã‚¤ã‚¯ '{stream_id}' ã‹ã‚‰ç™ºè©±çµ‚äº†é€šçŸ¥ã‚’å—ä¿¡ã€‚")
                        full_audio_data = manager.get_and_clear_audio_data(stream_id)
                        if not is_processing:
                            is_processing = True
                            await run_pipeline(full_audio_data)

                except Exception as e:
                    print(f"åˆ¶å¾¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

            # ãƒã‚¤ãƒŠãƒªå½¢å¼ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
            elif "bytes" in data:
                # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è“„ç©
                manager.append_audio_data(stream_id, data["bytes"])
                # ã—ãã„å€¤ã‚’è¶…ãˆãŸã‚‰è‡ªå‹•çš„ã«å‡¦ç†é–‹å§‹ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
                buf = manager.audio_buffers.get(stream_id)
                if buf is not None and (not is_processing) and len(buf) >= STREAM_THRESHOLD_BYTES:
                    full_audio_data = manager.get_and_clear_audio_data(stream_id)
                    is_processing = True
                    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
                    asyncio.create_task(run_pipeline(full_audio_data))

    except WebSocketDisconnect:
        print(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ‡æ–­ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        manager.disconnect(websocket)
        print("æ¥ç¶šã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

# --- ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹• ---
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)
