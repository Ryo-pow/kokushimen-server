import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, status
from fastapi.security import APIKeyHeader
import os
import time
from faster_whisper import WhisperModel
import google.generativeai as genai
from dotenv import load_dotenv
import httpx
from typing import Union, Dict, Set
import random
import json
import numpy as np

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

app = FastAPI()

# --- èªè¨¼ ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æœŸå¾…ã™ã‚‹APIã‚­ãƒ¼ã‚’å–å¾—
EXPECTED_API_KEY = os.getenv("SERVER_AUTH_TOKEN", "dev-token-secret")
# "Authorization" ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿å–ã‚‹ãŸã‚ã®è¨­å®š
api_key_header = APIKeyHeader(name="Authorization", auto_error=False)

async def get_api_key(auth_header: str = Depends(api_key_header)):
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œè¨¼ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸æ­£ãªã‚‰WebSocketæ¥ç¶šã‚’æ‹’å¦ã™ã‚‹"""
    if not auth_header:
        return None
    
    parts = auth_header.split()
    if len(parts) != 2 or parts[0].lower() != "bearer":
        return None
        
    if parts[1] == EXPECTED_API_KEY:
        return parts[1]
    return None

# --- æ¥ç¶šç®¡ç† ---
class ConnectionManager:
    def __init__(self):
        self.senders: Dict[str, WebSocket] = {}
        self.playbacks: Set[WebSocket] = set()
        self.audio_buffers: Dict[str, bytearray] = {}

    async def connect(self, websocket: WebSocket):
        await websocket.accept()

    def disconnect(self, websocket: WebSocket):
        sender_to_remove = None
        for stream_id, ws in self.senders.items():
            if ws == websocket:
                sender_to_remove = stream_id
                break
        if sender_to_remove:
            del self.senders[sender_to_remove]
            if sender_to_remove in self.audio_buffers:
                del self.audio_buffers[sender_to_remove]
        
        if websocket in self.playbacks:
            self.playbacks.remove(websocket)

    def add_sender(self, stream_id: str, websocket: WebSocket):
        self.senders[stream_id] = websocket
        self.audio_buffers[stream_id] = bytearray()
        print(f"âœ… é€ä¿¡ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ '{stream_id}' ãŒç™»éŒ²ã•ã‚Œã¾ã—ãŸã€‚")

    def add_playback(self, websocket: WebSocket):
        self.playbacks.add(websocket)
        print("âœ… å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒç™»éŒ²ã•ã‚Œã¾ã—ãŸã€‚")

    def append_audio_data(self, stream_id: str, data: bytes):
        if stream_id in self.audio_buffers:
            self.audio_buffers[stream_id].extend(data)

    def get_and_clear_audio_data(self, stream_id: str) -> bytes:
        if stream_id in self.audio_buffers:
            data = bytes(self.audio_buffers[stream_id])
            self.audio_buffers[stream_id].clear()
            return data
        return b''

    async def broadcast_audio_chunks(self, audio_data: bytes, chunk_size: int):
        """å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå…¨å“¡ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã§é€ä¿¡"""
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i+chunk_size]
            for ws in self.playbacks:
                try:
                    await ws.send_bytes(chunk)
                except Exception as e:
                    print(f"å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            # å®Ÿéš›ã®æ™‚é–“çµŒéã«åˆã‚ã›ã¦å°‘ã—å¾…ã¤ã“ã¨ã§ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒãƒƒãƒ•ã‚¡æº¢ã‚Œã‚’é˜²ã
            await asyncio.sleep(0.18) # 200msãƒãƒ£ãƒ³ã‚¯ã‚ˆã‚Šå°‘ã—çŸ­ãè¨­å®š

    async def broadcast_json(self, json_data: dict):
        """å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå…¨å“¡ã«JSONãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡"""
        for ws in self.playbacks:
            try:
                await ws.send_json(json_data)
            except Exception as e:
                print(f"å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®JSONé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

manager = ConnectionManager()

# --- è¨­å®š ---
AVAILABLE_SPEAKER_IDS = [2, 3, 1, 8, 10, 14]
VOICEVOX_BASE_URL = "http://127.0.0.1:50021"
# 16kHz, 16-bit, mono ã® 200ms åˆ†ã®ãƒã‚¤ãƒˆæ•°
TTS_CHUNK_SIZE = 16000 * 2 * 1 * 200 // 1000 

# --- ãƒ¢ãƒ‡ãƒ«ã¨APIã®æº–å‚™ ---
try:
    # â–¼â–¼â–¼ æ”¹å–„ç‚¹1: faster-whisper ã«å¤‰æ›´ â–¼â–¼â–¼
    # CPU: "int8", GPU: "float16" or "int8_float16"
    model = WhisperModel("base", device="cpu", compute_type="int8")
    print("âœ… faster-whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚")
except Exception as e:
    model = None
    print(f"âŒ faster-whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

try:
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        raise ValueError("ç’°å¢ƒå¤‰æ•°ã«GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    genai.configure(api_key=gemini_api_key)
    gemini_model = genai.GenerativeModel('gemini-1.5-flash')
    print("âœ… Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å®Œäº†ã€‚")
except Exception as e:
    gemini_model = None
    print(f"âŒ Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å¤±æ•—: {e}")

# --- é–¢æ•°å®šç¾© ---
async def generate_voicevox_audio(text: str, speaker_id: int) -> Union[bytes, None]:
    async with httpx.AsyncClient() as client:
        try:
            params = {"text": text, "speaker": speaker_id}
            res_query = await client.post(f"{VOICEVOX_BASE_URL}/audio_query", params=params)
            res_query.raise_for_status()
            audio_query = res_query.json()
            
            headers = {"Content-Type": "application/json"}
            res_synth = await client.post(
                f"{VOICEVOX_BASE_URL}/synthesis",
                params={"speaker": speaker_id},
                json=audio_query,
                headers=headers,
                timeout=20.0
            )
            res_synth.raise_for_status()
            
            return res_synth.content
        except Exception as e:
            print(f"âŒ VOICEVOX APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def pcm_s16le_to_float32(audio_data: bytes) -> np.ndarray:
    """ç”ŸPCM(s16le)ãƒ‡ãƒ¼ã‚¿ã‚’WhisperãŒå‡¦ç†ã§ãã‚‹float32å½¢å¼ã«å¤‰æ›"""
    return np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

# --- WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, token: str = Depends(get_api_key)):
    # â–¼â–¼â–¼ æ”¹å–„ç‚¹4: èªè¨¼å‡¦ç† â–¼â–¼â–¼
    if not token:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        print("âŒ èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒç„¡åŠ¹ãªãŸã‚æ¥ç¶šã‚’æ‹’å¦ã—ã¾ã—ãŸã€‚")
        return

    await manager.connect(websocket)
    stream_id = None
    is_sender = False

    try:
        while True:
            data = await websocket.receive()

            if isinstance(data, str) or (isinstance(data, bytes) and data.startswith(b'{')):
                try:
                    msg_text = data.decode('utf-8') if isinstance(data, bytes) else data
                    msg_json = json.loads(msg_text)
                    msg_type = msg_json.get("type")

                    if msg_type == "hello":
                        role = msg_json.get("role")
                        if role == "sender":
                            stream_id = msg_json.get("stream_id")
                            if stream_id:
                                manager.add_sender(stream_id, websocket)
                                is_sender = True
                        elif role == "playback":
                            manager.add_playback(websocket)
                    
                    elif msg_type == "stop" and is_sender and stream_id:
                        print(f"ğŸ¤ ãƒã‚¤ã‚¯ '{stream_id}' ã‹ã‚‰ç™ºè©±çµ‚äº†é€šçŸ¥ã‚’å—ä¿¡ã€‚")
                        
                        full_audio_data = manager.get_and_clear_audio_data(stream_id)
                        
                        if len(full_audio_data) < 1600: # 100msæœªæº€ã®éŸ³å£°ã¯ç„¡è¦–
                            print("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            continue

                        if not model or not gemini_model:
                            print("ãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ãŸã‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            continue
                        
                        # â–¼â–¼â–¼ æ”¹å–„ç‚¹3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ â–¼â–¼â–¼
                        t_start = time.time()

                        # 1. Whisperã§æ–‡å­—èµ·ã“ã—
                        audio_np = pcm_s16le_to_float32(full_audio_data)
                        segments, _ = model.transcribe(audio_np, beam_size=5, language="ja", vad_filter=True)
                        transcribed_text = "".join([s.text for s in segments]).strip()
                        t_asr = time.time()

                        if not transcribed_text:
                            print("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸã€‚")
                            continue
                        print(f"âœ¨ æ–‡å­—èµ·ã“ã—çµæœ: {transcribed_text}")

                        # 2. Geminiã§å¿œç­”ç”Ÿæˆ
                        prompt = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã€Œ{transcribed_text}ã€ã«å¯¾ã—ã¦ã€è¦ªåˆ‡ã§ç°¡æ½”ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
                        response = gemini_model.generate_content(prompt)
                        ai_response_text = response.text
                        t_llm = time.time()
                        print(f"ğŸ’¬ Geminiã‹ã‚‰ã®å¿œç­”: {ai_response_text}")

                        # 3. VOICEVOXã§éŸ³å£°åˆæˆ
                        selected_speaker_id = random.choice(AVAILABLE_SPEAKER_IDS)
                        voice_data = await generate_voicevox_audio(ai_response_text, speaker_id=selected_speaker_id)
                        t_tts = time.time()

                        # 4. å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ
                        if voice_data:
                            # â–¼â–¼â–¼ æ”¹å–„ç‚¹2: éŸ³å£°ã‚’ãƒãƒ£ãƒ³ã‚¯ã§åˆ†å‰²é€ä¿¡ â–¼â–¼â–¼
                            print(f"ğŸ”Š å…¨å†ç”Ÿã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ ({len(voice_data)} bytes) ã‚’åˆ†å‰²é€ä¿¡ã—ã¾ã™ã€‚")
                            await manager.broadcast_audio_chunks(voice_data, TTS_CHUNK_SIZE)
                            await manager.broadcast_json({"type": "tts_done"})
                            print("â„¹ï¸  ãƒŸãƒ¥ãƒ¼ãƒˆè§£é™¤ã®ãŸã‚ã®å®Œäº†é€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
                        
                        t_end = time.time()
                        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’å‡ºåŠ›
                        print(f"â±ï¸  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: [ASR: {t_asr - t_start:.2f}s] [LLM: {t_llm - t_asr:.2f}s] [TTS: {t_tts - t_llm:.2f}s] [Total: {t_end - t_start:.2f}s]")

                except Exception as e:
                    print(f"åˆ¶å¾¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

            elif isinstance(data, bytes) and is_sender and stream_id:
                manager.append_audio_data(stream_id, data)

    except WebSocketDisconnect:
        print(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ‡æ–­ã—ã¾ã—ãŸã€‚")
    finally:
        manager.disconnect(websocket)
        print("æ¥ç¶šã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    import asyncio
    uvicorn.run(app, host="0.0.0.0", port=8000)
